import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds

train_data, info = tfds.load('horses_or_humans', split='train', as_supervised=True, with_info=True)
test_data = tfds.load('horses_or_humans', split='test', as_supervised=True)

num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples

batch_size = 32
train_batches = train_data.shuffle(num_train_examples // 4).batch(batch_size).repeat()
test_batches = test_data.batch(batch_size)

model = tf.keras.models.Sequential([
  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(300, 300, 3)),
  tf.keras.layers.MaxPooling2D(2, 2),
  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
  tf.keras.layers.MaxPooling2D(2,2),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(256, activation='relu'),
  tf.keras.layers.Dropout(0.5),
  tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_batches,
                    epochs=10,
                    steps_per_epoch=num_train_examples//batch_size,
                    validation_data=test_batches,
                    validation_steps=num_test_examples//batch_size)

import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and Validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs, loss, 'r', label='Training Loss')
plt.plot(epochs, val_loss, 'b', label='Validation Loss')
plt.title('Training and Validation loss')
plt.legend()

plt.show()
